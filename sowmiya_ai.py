# -*- coding: utf-8 -*-
"""Sowmiya_AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UsFvXhM9PASGqZwdovuBCuwSawV3y86F
"""

"""
time_series_nas_neuralprophet.py

Usage:
    1) Create a fresh venv (recommended).
    2) pip install -r requirements (or run the pip install command below).
    3) python time_series_nas_neuralprophet.py

Requirements (install with):
pip install numpy pandas matplotlib scikit-learn statsmodels holidays optuna neuralprophet shap tqdm

Notes:
- neuralprophet requires pytorch; `pip install neuralprophet` will bring required deps.
- For larger experiments increase OPTUNA_TRIALS and EPOCHS.
"""

import warnings
warnings.filterwarnings("ignore")

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import timedelta
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.inspection import permutation_importance
import statsmodels.api as sm
import optuna
from neuralprophet import NeuralProphet, set_random_seed
import holidays
from tqdm.auto import tqdm
import shap
import random
import joblib
import math

# -------------------------
# Config
# -------------------------
RANDOM_SEED = 42
set_random_seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

# Data generation params
START_DATE = "2016-01-01"
END_DATE = "2022-12-31"  # ~7 years daily
FREQ = "D"

# Forecast horizon
HORIZON_DAYS = 90  # evaluate 90-day holdout

# Hyperparameter tuning
OPTUNA_TRIALS = 20  # increase for better results
EPOCHS = 50         # increase for better training

# Save outputs
OUTDIR = "outputs"
os.makedirs(OUTDIR, exist_ok=True)

# -------------------------
# Utilities & Metrics
# -------------------------
def rmse(y_true, y_pred):
    return math.sqrt(mean_squared_error(y_true, y_pred))

def mase(y_true, y_pred, train_series, seasonality=365):
    """
    Mean Absolute Scaled Error as defined by Hyndman:
    scale = mean absolute naive seasonal differences on training set
    """
    n = len(train_series)
    if n <= seasonality:
        # fallback to naive (lag-1) if not enough data for seasonal naive
        diff = np.abs(np.diff(train_series, n=1))
    else:
        diff = np.abs(train_series[seasonality:] - train_series[:-seasonality])
    scale = diff.mean()
    if scale == 0:
        return np.nan
    return np.mean(np.abs(y_true - y_pred)) / scale

# -------------------------
# 1) Data Generation
# -------------------------
def generate_multiseasonal_series(start=START_DATE, end=END_DATE, seed=RANDOM_SEED):
    rng = pd.date_range(start=start, end=end, freq=FREQ)
    n = len(rng)
    np.random.seed(seed)

    # Base trend (slow upward)
    t = np.arange(n)
    trend = 0.0006 * t  # small slope

    # Daily seasonality (weekly pattern)
    day_of_week = rng.dayofweek
    weekly = 0.8 * np.sin(2 * np.pi * day_of_week / 7) + 0.3 * (day_of_week == 5)  # stronger Saturday effect

    # Yearly seasonality (approx)
    doy = rng.dayofyear
    yearly = 2.0 * np.sin(2 * np.pi * doy / 365.25) + 0.5 * np.cos(4 * np.pi * doy / 365.25)

    # Random noise
    noise = np.random.normal(0, 0.4, n)

    # External regressor 1: holidays (binary)
    us_holidays = holidays.US()
    holiday_flag = np.array([1 if d in us_holidays else 0 for d in rng])

    # External regressor 2: slow-moving economic indicator (e.g., GDP index)
    econ_index = 100 + np.cumsum(np.random.normal(0, 0.03, n))  # random walk around 100, smooth
    econ_index = (econ_index - econ_index.mean()) / econ_index.std()  # normalize

    # Combine to form target
    y = 10 + 0.5 * trend + 1.5 * weekly + 3.0 * yearly + 0.8 * holiday_flag + 1.2 * econ_index + noise

    df = pd.DataFrame({
        "ds": rng,
        "y": y,
        "holiday": holiday_flag,
        "econ_index": econ_index
    })
    return df

# -------------------------
# 2) Train / Eval Split
# -------------------------
def train_test_split_time(df, horizon=HORIZON_DAYS):
    df = df.copy().reset_index(drop=True)
    train = df.iloc[:-horizon].reset_index(drop=True)
    test = df.iloc[-horizon:].reset_index(drop=True)
    return train, test

# -------------------------
# 3) NeuralProphet training function
# -------------------------
def build_and_train_neuralprophet(train_df, val_df=None, params=None, epochs=EPOCHS, verbose=False):
    """
    params: dict with hyperparams, e.g. {'n_lags': 14, 'n_forecasts':1, 'n_hidden': 32, 'dropout':0.1, 'learning_rate':1.0}
    """
    if params is None:
        params = {}

    # Create model
    m = NeuralProphet(
        n_lags=params.get("n_lags", 14),
        n_forecasts=params.get("n_forecasts", 1),
        yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False,  # we'll add custom components
        learning_rate=params.get("learning_rate", 1.0),
        num_hidden_layers=params.get("num_hidden_layers", 1),
        d_hidden=params.get("d_hidden", 32),
        dropout=params.get("dropout", 0.0),
        loss_func="MSE",
        log_level="ERROR"
    )

    # Add seasonalities (explicit)
    m.add_seasonality(name='yearly', period=365.25, fourier_order=params.get("yearly_fourier", 10))
    m.add_seasonality(name='weekly', period=7, fourier_order=params.get("weekly_fourier", 3))

    # Add regressors
    m.add_regressor('holiday')
    m.add_regressor('econ_index')

    # Fit
    df_train = train_df[['ds', 'y', 'holiday', 'econ_index']].copy()
    if val_df is not None:
        df_val = val_df[['ds', 'y', 'holiday', 'econ_index']].copy()
        metrics = m.fit(df_train, validation_df=df_val, freq='D', epochs=epochs, progress=not verbose)
    else:
        metrics = m.fit(df_train, freq='D', epochs=epochs, progress=not verbose)

    return m, metrics

# -------------------------
# 4) Optuna Tuning
# -------------------------
def optuna_objective(trial, train_df, val_df):
    # Search space
    n_lags = trial.suggest_int("n_lags", 7, 28)
    n_forecasts = 1
    d_hidden = trial.suggest_categorical("d_hidden", [16, 32, 64, 128])
    num_hidden_layers = trial.suggest_int("num_hidden_layers", 1, 3)
    dropout = trial.suggest_float("dropout", 0.0, 0.5)
    learning_rate = trial.suggest_float("learning_rate", 1e-3, 2.0, log=True)
    yearly_fourier = trial.suggest_int("yearly_fourier", 6, 20)
    weekly_fourier = trial.suggest_int("weekly_fourier", 2, 6)

    params = {
        "n_lags": n_lags,
        "n_forecasts": n_forecasts,
        "d_hidden": d_hidden,
        "num_hidden_layers": num_hidden_layers,
        "dropout": dropout,
        "learning_rate": learning_rate,
        "yearly_fourier": yearly_fourier,
        "weekly_fourier": weekly_fourier
    }

    # Train for a small number of epochs to estimate
    try:
        m, _ = build_and_train_neuralprophet(train_df, val_df=val_df, params=params, epochs=EPOCHS//5, verbose=False)
        # Forecast on val set
        future = val_df[['ds', 'holiday', 'econ_index']].copy()
        preds = m.predict(future)
        y_pred = preds['yhat1'].values if 'yhat1' in preds.columns else preds['yhat'].values
        y_true = val_df['y'].values
        score = mean_squared_error(y_true, y_pred, squared=False)  # RMSE
    except Exception as e:
        # in case of training failure
        print("Trial failed:", e)
        score = 1e6

    return score

def tune_neuralprophet(train_df, val_df, n_trials=OPTUNA_TRIALS):
    study = optuna.create_study(direction="minimize", sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED))
    func = lambda trial: optuna_objective(trial, train_df, val_df)
    study.optimize(func, n_trials=n_trials, show_progress_bar=True)
    print("Best params:", study.best_params)
    return study.best_params

# -------------------------
# 5) SARIMAX Benchmark
# -------------------------
def train_sarimax(train_df, test_df, exog_cols=['holiday', 'econ_index']):
    # Build SARIMAX using seasonal order (P, D, Q, s) with s=7 for weekly seasonality as demonstration
    y_train = train_df['y']
    exog_train = train_df[exog_cols]
    exog_test = test_df[exog_cols]

    # We'll pick simple orders; for production use auto_arima or grid search
    order = (1, 1, 1)
    seasonal_order = (1, 1, 1, 7)

    model = sm.tsa.statespace.SARIMAX(y_train, exog=exog_train, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)
    res = model.fit(disp=False)
    pred = res.get_forecast(steps=len(test_df), exog=exog_test)
    y_pred = pred.predicted_mean.values
    return res, y_pred

# -------------------------
# 6) XAI: Permutation importance + surrogate SHAP
# -------------------------
def compute_permutation_importance(neural_model, val_df, metric_fn=mean_squared_error, n_repeats=10):
    """
    Permutation importance: permute each regressor column in the validation features and measure drop in performance.
    We'll construct a callable that given X returns predictions.
    """
    features = ['holiday', 'econ_index']
    X_val = val_df[features].copy()
    y_val = val_df['y'].values

    def predict_from_X(X_df):
        # NeuralProphet requires 'ds' and regressors. We'll use ds from val_df
        tmp = val_df[['ds']].copy()
        for col in features:
            tmp[col] = X_df[col].values
        preds = neural_model.predict(tmp)
        return preds['yhat1'].values

    # Baseline metric
    y_pred_base = predict_from_X(X_val)
    base_rmse = rmse(y_val, y_pred_base)

    importances = {}
    for col in features:
        scores = []
        for _ in range(n_repeats):
            Xp = X_val.copy()
            Xp[col] = np.random.permutation(Xp[col].values)
            y_pred = predict_from_X(Xp)
            scores.append(rmse(y_val, y_pred))
        # importance = increase in RMSE when permuted
        importances[col] = np.mean(scores) - base_rmse

    return base_rmse, importances

def surrogate_shap_explanation(neural_model, train_df, val_df, n_samples=100):
    """
    Distill neural model into a simple tree regressor (RandomForest) using features available:
    - regressors
    - time features (dow, doy)
    Then compute SHAP on the surrogate model (TreeExplainer).
    """
    from sklearn.ensemble import RandomForestRegressor

    def build_features(df):
        X = pd.DataFrame()
        X['holiday'] = df['holiday'].values
        X['econ_index'] = df['econ_index'].values
        X['dow'] = df['ds'].dt.dayofweek
        X['doy'] = df['ds'].dt.dayofyear
        X['month'] = df['ds'].dt.month
        return X

    # Prepare dataset
    X_train = build_features(train_df)
    X_val = build_features(val_df)

    # Generate labels by querying neural_model.predict on combined df
    # Compose full df with ds + regressors
    preds_train = neural_model.predict(train_df[['ds', 'holiday', 'econ_index']])
    y_train_pred = preds_train['yhat1'].values

    # Fit surrogate
    rf = RandomForestRegressor(n_estimators=100, random_state=RANDOM_SEED)
    rf.fit(X_train, y_train_pred)

    # SHAP: TreeExplainer for RandomForest
    explainer = shap.TreeExplainer(rf)
    shap_values = explainer.shap_values(X_val)

    # Summarize importance (mean absolute SHAP)
    mean_abs_shap = np.mean(np.abs(shap_values), axis=0)
    feature_importance = pd.Series(mean_abs_shap, index=X_val.columns).sort_values(ascending=False)
    return rf, explainer, shap_values, X_val, feature_importance

# -------------------------
# 7) Orchestration script
# -------------------------
def main():
    print("Generating dataset...")
    df = generate_multiseasonal_series()

    print("Train/test split...")
    train_df, test_df = train_test_split_time(df, horizon=HORIZON_DAYS)
    # Further split train into training + validation for tuning
    train_small, val_df = train_test_split(train_df, test_size=0.15, shuffle=False)  # keep time order

    print(f"Train rows: {len(train_small)}, Val rows: {len(val_df)}, Test rows: {len(test_df)}")

    # Baseline: naive seasonal forecast (seasonal naive with lag=365)
    naive_pred = train_df['y'].shift(365).iloc[-HORIZON_DAYS:].values
    if np.any(pd.isna(naive_pred)):
        # fallback to last value
        naive_pred = np.repeat(train_df['y'].iloc[-1], HORIZON_DAYS)

    # Tune NeuralProphet
    print("Tuning NeuralProphet hyperparameters (Optuna)...")
    best_params = tune_neuralprophet(train_small, val_df, n_trials=OPTUNA_TRIALS)

    # Train final NeuralProphet on full training (train_df), use best_params
    print("Training final NeuralProphet with best params...")
    m_final, metrics = build_and_train_neuralprophet(train_df, val_df=None, params=best_params, epochs=EPOCHS, verbose=True)

    # Forecast on test
    future = test_df[['ds', 'holiday', 'econ_index']].copy()
    preds = m_final.predict(future)
    yhat = preds['yhat1'].values
    y_true = test_df['y'].values

    # Compute metrics
    np_rmse = rmse(y_true, yhat)
    np_mase = mase(y_true, yhat, train_df['y'].values, seasonality=365)
    naive_rmse = rmse(y_true, naive_pred)
    naive_mase = mase(y_true, naive_pred, train_df['y'].values, seasonality=365)

    print("\n--- Results ---")
    print(f"NeuralProphet RMSE: {np_rmse:.4f}, MASE: {np_mase:.4f}")
    print(f"Naive seasonal RMSE: {naive_rmse:.4f}, MASE: {naive_mase:.4f}")

    # SARIMAX benchmark
    print("\nTraining SARIMAX benchmark...")
    sarimax_res, sarimax_pred = train_sarimax(train_df, test_df)
    sar_rmse = rmse(y_true, sarimax_pred)
    sar_mase = mase(y_true, sarimax_pred, train_df['y'].values, seasonality=365)
    print(f"SARIMAX RMSE: {sar_rmse:.4f}, MASE: {sar_mase:.4f}")

    # Save a summary CSV
    summary = pd.DataFrame([
        {"model": "NeuralProphet", "RMSE": np_rmse, "MASE": np_mase},
        {"model": "NaiveSeasonal", "RMSE": naive_rmse, "MASE": naive_mase},
        {"model": "SARIMAX", "RMSE": sar_rmse, "MASE": sar_mase},
    ])
    summary.to_csv(os.path.join(OUTDIR, "model_comparison.csv"), index=False)
    print(f"Saved model comparison to {os.path.join(OUTDIR, 'model_comparison.csv')}")

    # Plot forecasts
    fig, ax = plt.subplots(figsize=(12, 5))
    ax.plot(test_df['ds'], y_true, label='Actual', linewidth=2)
    ax.plot(test_df['ds'], yhat, label='NeuralProphet Forecast')
    ax.plot(test_df['ds'], sarimax_pred, label='SARIMAX Forecast')
    ax.plot(test_df['ds'], naive_pred, label='Naive Seasonal Forecast', alpha=0.6)
    ax.legend()
    ax.set_title("Test Set Forecast Comparison")
    plt.tight_layout()
    plt.savefig(os.path.join(OUTDIR, "forecast_comparison.png"))
    print(f"Saved forecast plot to {os.path.join(OUTDIR, 'forecast_comparison.png')}")

    # XAI - Permutation Importance
    print("\nPermutation importance (NeuralProphet regressors)...")
    base_rmse, perm_imp = compute_permutation_importance(m_final, test_df, n_repeats=20)
    print(f"Base RMSE on test: {base_rmse:.4f}")
    for k, v in perm_imp.items():
        print(f"Permuted {k}: RMSE increase = {v:.4f}")

    # XAI - Surrogate SHAP explanation
    print("\nBuilding surrogate and computing SHAP...")
    rf_surrogate, explainer, shap_values, X_val, feat_imp = surrogate_shap_explanation(m_final, train_df, test_df)
    print("\nSurrogate model feature importance (mean |SHAP|):")
    print(feat_imp)

    # Save SHAP summary figure
    try:
        shap.summary_plot(shap_values, X_val, show=False)
        plt.tight_layout()
        plt.savefig(os.path.join(OUTDIR, "shap_summary.png"))
        print(f"Saved SHAP summary to {os.path.join(OUTDIR, 'shap_summary.png')}")
    except Exception as e:
        print("Warning: could not save SHAP summary plot:", e)

    # Save trained models
    try:
        # NeuralProphet model can be saved via save method
        m_final.save(os.path.join(OUTDIR, "neuralprophet_model"))
        joblib.dump(sarimax_res, os.path.join(OUTDIR, "sarimax.pkl"))
        joblib.dump(rf_surrogate, os.path.join(OUTDIR, "surrogate_rf.pkl"))
        print(f"Saved models to {OUTDIR}")
    except Exception as e:
        print("Warning saving models:", e)

    print("\nAll done. Outputs are in the 'outputs' directory.")

if __name__ == "__main__":
    main()